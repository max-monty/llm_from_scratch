{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, context_size):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        enc_txt = tokenizer.encode(text)\n",
    "        for i in range(0, len(enc_txt) - context_size):\n",
    "            x = enc_txt[i:i+context_size]\n",
    "            y = enc_txt[i+1:i+context_size+1]\n",
    "            self.x.append(torch.tensor(x))\n",
    "            self.y.append(torch.tensor(y))\n",
    "        self.x = torch.stack(self.x)\n",
    "        self.y = torch.stack(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def load_data(self, batch_size, shuffle=True):\n",
    "        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, max_len):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_len, embed_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tok_embed = self.token_embedding(x)\n",
    "        pos_embed = self.position_embedding(torch.arange(x.shape[1]))\n",
    "        return tok_embed + pos_embed\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.token_embedding.parameters() + self.position_embedding.parameters()\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, n_heads, dropout, masked, max_len):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_out // n_heads\n",
    "        self.masked = masked\n",
    "        self.q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.k = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.v = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(max_len, max_len), diagonal=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        Q = self.q(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        attention_scores = Q @ K.transpose(-2, -1)\n",
    "        if self.masked:\n",
    "            mask = self.mask[:T, :T]\n",
    "            attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.head_dim ** 0.5), dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        context_vectors = attention_weights @ V\n",
    "        context_vectors = context_vectors.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        return self.out_proj(context_vectors)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.q.parameters() + self.k.parameters() + self.v.parameters() + self.out_proj.parameters()\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, max_len, n_heads, dropout, masked):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = EmbeddingLayer(vocab_size, embed_size, max_len)\n",
    "        self.attention_layer = MultiHeadAttention(embed_size, embed_size, n_heads, dropout, masked, max_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "        attention_vectors = self.attention_layer(embedded)\n",
    "        return attention_vectors\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.embedding_layer.parameters() + self.attention_layer.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 1024\n",
    "batch_size = 32\n",
    "embed_size = 768\n",
    "n_heads = 12\n",
    "dropout = 0.1\n",
    "masked = True\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "vocab_size = tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 41743872\n"
     ]
    }
   ],
   "source": [
    "dataset = GPTDataset(raw_text, tokenizer, context_size)\n",
    "dataloader = iter(dataset.load_data(batch_size))\n",
    "network = Network(vocab_size, embed_size, context_size, n_heads, dropout, masked)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in network.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 768])\n",
      "tensor([[[-4.0036e-01,  7.2065e-01,  1.2895e+00,  ..., -4.4990e-01,\n",
      "           3.0665e-01, -1.1862e+00],\n",
      "         [-9.5281e-01,  4.5434e-01,  8.1317e-01,  ..., -1.0560e-01,\n",
      "          -1.8351e-01, -3.8012e-01],\n",
      "         [-4.0295e-01,  2.1444e-01,  4.0911e-01,  ..., -7.1460e-01,\n",
      "           6.4789e-02, -1.1589e-01],\n",
      "         ...,\n",
      "         [-4.0129e-02, -7.4827e-02,  9.2245e-02,  ..., -6.1951e-02,\n",
      "           3.2196e-02,  7.0760e-03],\n",
      "         [-8.8575e-02, -1.0987e-01,  6.9352e-02,  ...,  2.9009e-02,\n",
      "           3.8491e-02,  2.0442e-02],\n",
      "         [-5.1991e-02, -6.3246e-02,  4.5091e-02,  ...,  2.2020e-03,\n",
      "           4.8783e-02,  1.3770e-03]],\n",
      "\n",
      "        [[-5.3485e-02,  4.3702e-01,  5.7494e-01,  ..., -2.1828e-01,\n",
      "           5.1636e-01, -1.0875e+00],\n",
      "         [-1.4255e-01,  7.1311e-01,  1.1093e-01,  ..., -2.4189e-01,\n",
      "           5.7655e-01, -6.1783e-01],\n",
      "         [-2.0377e-01,  3.4689e-01, -3.4207e-02,  ..., -4.1896e-02,\n",
      "           1.2861e-01, -1.0131e-01],\n",
      "         ...,\n",
      "         [-7.9224e-02, -5.2508e-02,  4.1948e-02,  ...,  1.0977e-02,\n",
      "           2.1275e-02,  8.6062e-03],\n",
      "         [-1.2841e-01, -4.1338e-02,  4.3395e-02,  ...,  4.9144e-02,\n",
      "           8.9880e-02,  2.9251e-02],\n",
      "         [-4.4405e-02, -4.8038e-02,  1.4374e-02,  ...,  8.9496e-03,\n",
      "           3.6897e-02, -1.7778e-02]],\n",
      "\n",
      "        [[-7.1808e-01,  3.7188e-01,  1.7898e-01,  ..., -6.1587e-01,\n",
      "           3.8497e-01, -7.7151e-01],\n",
      "         [-4.0777e-01, -1.2511e-02, -2.3820e-01,  ..., -6.3533e-01,\n",
      "           3.5557e-01,  2.0862e-01],\n",
      "         [-1.6797e-01, -3.6440e-02,  6.1384e-02,  ..., -4.2669e-01,\n",
      "           6.1371e-02,  9.7446e-02],\n",
      "         ...,\n",
      "         [-4.8263e-02, -5.5235e-02,  3.8305e-02,  ...,  4.2117e-03,\n",
      "           4.4169e-02, -1.7124e-02],\n",
      "         [-9.4058e-02, -7.5729e-02,  4.0691e-02,  ...,  7.7115e-02,\n",
      "           5.0695e-02, -1.1264e-02],\n",
      "         [-4.6088e-02, -6.9954e-02,  2.6980e-04,  ...,  3.6414e-02,\n",
      "           4.9195e-02, -4.2700e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0455e-01,  1.1421e-01, -1.1737e-01,  ..., -1.4342e-01,\n",
      "           3.6504e-01, -7.3343e-01],\n",
      "         [ 4.0575e-01, -2.1025e-01, -7.9454e-03,  ...,  2.0731e-01,\n",
      "          -1.0573e-01, -1.0017e-01],\n",
      "         [ 2.1973e-01, -4.3187e-04,  2.2314e-01,  ..., -2.9264e-01,\n",
      "           3.3603e-02, -7.5384e-02],\n",
      "         ...,\n",
      "         [-3.8648e-02, -8.6019e-02,  1.0950e-01,  ...,  1.9606e-02,\n",
      "           6.4425e-02,  6.0702e-02],\n",
      "         [-2.7261e-02, -1.2105e-01,  8.6928e-02,  ..., -1.3493e-02,\n",
      "           7.3008e-02, -2.1846e-02],\n",
      "         [-2.2655e-02, -8.6944e-02,  6.7453e-02,  ..., -3.0109e-03,\n",
      "           4.9162e-02,  1.9569e-02]],\n",
      "\n",
      "        [[ 4.2182e-01,  1.2314e+00,  9.9163e-01,  ...,  7.5630e-02,\n",
      "           5.5740e-01,  2.0111e-01],\n",
      "         [ 6.8001e-02,  6.1283e-01,  7.9537e-01,  ..., -2.3540e-02,\n",
      "          -6.6206e-02, -1.3368e-01],\n",
      "         [-5.3510e-02,  3.4403e-01,  7.2935e-01,  ...,  1.2236e-01,\n",
      "           2.1035e-01,  6.7811e-02],\n",
      "         ...,\n",
      "         [-9.4465e-02, -7.7710e-02,  6.6191e-02,  ..., -5.8516e-03,\n",
      "           5.2199e-02,  4.4178e-03],\n",
      "         [-9.8248e-02, -4.8454e-02,  4.0654e-02,  ...,  4.3895e-02,\n",
      "           3.3837e-02,  2.9039e-02],\n",
      "         [-4.9146e-02, -8.0865e-02,  2.0617e-02,  ..., -4.4793e-03,\n",
      "           4.6590e-02, -3.7880e-03]],\n",
      "\n",
      "        [[-4.6187e-01,  1.1115e+00, -4.3753e-04,  ...,  5.4331e-02,\n",
      "           3.7202e-01,  3.1630e-01],\n",
      "         [-2.4484e-01,  2.7968e-01,  2.7651e-01,  ..., -1.6488e-01,\n",
      "           8.4490e-03,  2.3549e-01],\n",
      "         [-2.4217e-01,  2.0320e-01,  3.3282e-01,  ..., -3.8389e-01,\n",
      "           4.9677e-01,  1.5831e-01],\n",
      "         ...,\n",
      "         [-5.6602e-02, -9.8750e-02,  6.9054e-02,  ...,  2.8794e-02,\n",
      "           5.9520e-03,  1.7379e-02],\n",
      "         [-1.0142e-01, -7.3143e-02,  7.5978e-02,  ...,  3.6816e-02,\n",
      "           7.1111e-02,  5.3734e-06],\n",
      "         [-4.3075e-02, -6.5549e-02,  6.0101e-02,  ..., -1.5144e-02,\n",
      "           4.4595e-02,  6.5690e-02]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = network(next(dataloader)[0])\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
