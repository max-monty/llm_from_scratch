{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayr_UpuxHXtr"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KK4p8bSFxtZ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GJlmSE8MFM6J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbV30nykFtGf"
      },
      "source": [
        "## Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JjT8tGr9Ef0m"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_128M = {\n",
        "    \"tokenizer\": \"gpt2\",    # Tokenizer\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"context_len\": 256,    # Context length\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False,      # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGqkG-F4Ikfk"
      },
      "source": [
        "## Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U_AxT6PiJD-L"
      },
      "outputs": [],
      "source": [
        "sidewalk_path = './sidewalk.txt'\n",
        "verdict_path = './verdict.txt'\n",
        "\n",
        "with open(sidewalk_path, 'r') as f:\n",
        "  sidewalk = f.read()\n",
        "\n",
        "with open(verdict_path, 'r') as f:\n",
        "  verdict = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FihGcc9bF3Uy"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQBU2evtF-Hp"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PpfqANTcFFOG"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, tokenizer, context_size):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        enc_txt = tokenizer.encode(text)\n",
        "        for i in range(0, len(enc_txt) - context_size):\n",
        "            x = enc_txt[i:i+context_size]\n",
        "            y = enc_txt[i+1:i+context_size+1]\n",
        "            self.x.append(torch.tensor(x))\n",
        "            self.y.append(torch.tensor(y))\n",
        "        self.x = torch.stack(self.x)\n",
        "        self.y = torch.stack(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def load_data(self, batch_size=32, shuffle=True):\n",
        "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle, drop_last=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA-3_MnQGAw5"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk2TYVHLGKos"
      },
      "source": [
        "### Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AdGUPAmjGHbP"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.ones(cfg[\"emb_dim\"]))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(cfg[\"emb_dim\"]))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        normalized = (x - mean) / (std + self.eps)\n",
        "        return normalized * self.weight + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgRex_HfGWsP"
      },
      "source": [
        "### Token and Posistion Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6rMWfNqWGXUm"
      },
      "outputs": [],
      "source": [
        "class EmbeddingLayer(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, max_len):\n",
        "        super().__init__()\n",
        "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding = torch.nn.Embedding(max_len, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok_embed = self.token_embedding(x)\n",
        "        pos_embed = self.position_embedding(torch.arange(x.shape[1], device=x.device))\n",
        "        return tok_embed + pos_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB25YuFsGnpN"
      },
      "source": [
        "### Multi-head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2s03Sub2Gnwa"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, n_heads, drop_rate, qkv_bias):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_out // n_heads\n",
        "        self.q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = torch.nn.Dropout(drop_rate)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        Q = self.q(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        attention_scores = Q @ K.transpose(-2, -1)\n",
        "        mask = self.mask[:T, :T]\n",
        "        attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "        attention_weights = torch.softmax(attention_scores / (self.head_dim ** 0.5), dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        context_vectors = attention_weights @ V\n",
        "        context_vectors = context_vectors.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.out_proj(context_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV9B988jG-EB"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fYHH-oqwG-Pu"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_inSEITVHGvA"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uXBI9RmhHG1N"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_len\"],\n",
        "            n_heads=cfg[\"n_heads\"],\n",
        "            drop_rate=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        self.ff = MLP(cfg)\n",
        "        self.norm_1 = LayerNorm(cfg)\n",
        "        self.norm_2 = LayerNorm(cfg)\n",
        "        self.dropout = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        short_cut = x\n",
        "        x = self.norm_1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "\n",
        "        short_cut = x\n",
        "        x = self.norm_2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1jDAQl9HOyJ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SP_R3CknHOfo"
      },
      "outputs": [],
      "source": [
        "class GPT(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = EmbeddingLayer(cfg[\"vocab_size\"], cfg[\"emb_dim\"], cfg[\"context_len\"])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.ln_f = LayerNorm(cfg)\n",
        "        self.out_head = torch.nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop_emb(self.embedding_layer(x))\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        return self.out_head(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKibo7diKR4v"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx7fiXTfNxU_"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J6ZWiD7hKUKV"
      },
      "outputs": [],
      "source": [
        "def load_data(cfg, data, tokenizer, batch_size):\n",
        "    dataset = Dataset(data, tokenizer, context_size=cfg[\"context_len\"])\n",
        "    dataloader = dataset.load_data(batch_size, shuffle=True)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLNm_KK7OWC8"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AfVxjSBqOWJY"
      },
      "outputs": [],
      "source": [
        "def split_data(data):\n",
        "  train_data = data[:int(len(data) * 0.9)]\n",
        "  val_data = data[int(len(data) * 0.9):]\n",
        "  return train_data, val_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvZcUwjpOvZo"
      },
      "source": [
        "### Create Train-Val Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "27Fuh9cgOvgD"
      },
      "outputs": [],
      "source": [
        "def train_val_split(cfg, data, tokenizer, batch_size):\n",
        "  train_data, val_data = split_data(data)\n",
        "  train_dataloader = load_data(cfg, train_data, tokenizer, batch_size)\n",
        "  val_dataloader = load_data(cfg, val_data, tokenizer, batch_size)\n",
        "  return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kco9LtpXS2rD"
      },
      "source": [
        "### Calculate Loss (Batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KFzSnw_TS2yF"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(model, x, y, device):\n",
        "    logits = model(x.to(device))\n",
        "    targets = y.to(device)\n",
        "    # B, T, C = logits.shape\n",
        "    # loss = torch.nn.functional.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), targets.flatten())\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXfwUPkFTjTc"
      },
      "source": [
        "### Calculate Loss (Loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U-8pZsGzTjaJ"
      },
      "outputs": [],
      "source": [
        "def calc_loss_loader(model, dataloader, device, num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    if i >= num_batches:\n",
        "      break\n",
        "    loss = calc_loss_batch(model, x, y, device)\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4edQP0DZ576"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UaJMSNUcZ6BX"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, eval_iter, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(model, train_loader, device, eval_iter)\n",
        "    val_loss = calc_loss_loader(model, val_loader, device, eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xHVTBQBeDC8"
      },
      "source": [
        "### Text to Tokens Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q0F_G5LweDJy"
      },
      "outputs": [],
      "source": [
        "def text_to_tokens(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rM6GXkjeqQZ"
      },
      "source": [
        "### Token Ids to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XQHS3taNeqXW"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(tokens, tokenizer):\n",
        "  flat = tokens.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzW5oSt1b61d"
      },
      "source": [
        "### Generate Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "bGPnUQhGb67U"
      },
      "outputs": [],
      "source": [
        "def generate(model, tokenizer, context, max_tokens, device, temperature=1.0, top_k=None):\n",
        "    model.eval()\n",
        "    context_size = model.embedding_layer.position_embedding.weight.shape[0]\n",
        "    idx = text_to_tokens(context, tokenizer).to(device)\n",
        "    \n",
        "    for _ in range(max_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        \n",
        "        if top_k is not None:\n",
        "            top_k_logits, top_k_indices = torch.topk(logits, k=top_k)\n",
        "            logits = torch.full_like(logits, float('-inf'))\n",
        "            logits.scatter_(1, top_k_indices, top_k_logits)\n",
        "            \n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    \n",
        "    return tokens_to_text(idx, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXptd16PLDu2"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liqnCJXpLPoR"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HJvtCzViLUKb"
      },
      "outputs": [],
      "source": [
        "cfg = GPT_CONFIG_128M\n",
        "tokenizer = tiktoken.get_encoding(cfg[\"tokenizer\"])\n",
        "data = verdict #sidewalk\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 1\n",
        "eval_freq = 10\n",
        "eval_iter = 1 \n",
        "max_tokens = 10\n",
        "start_context = \"Every effort moves you\"\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZWmmNR3L-4O"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tpjYdhdMLXq0"
      },
      "outputs": [],
      "source": [
        "model = GPT(cfg).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EweKFVv9MXp5"
      },
      "source": [
        "## Initialize Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x9rZf9mvMD03"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXuR9ltBM4_h"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BHrZbjj4MdBh"
      },
      "outputs": [],
      "source": [
        "train, val = train_val_split(cfg, data, tokenizer, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIPp1xVPYzhI"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1Gi07O4jYzox"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, num_epochs, device,\n",
        "          eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(model, x, y, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += x.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, eval_iter, device)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Epoch: {epoch + 1}, Step: {global_step:06d}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}\")\n",
        "        print(generate(model, tokenizer, start_context, max_tokens , device))\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TiigHs72Tb52"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses, track_tokens_seen = train_model(model, train, val, optimizer, epochs, device, eval_freq, eval_iter, start_context, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "QXjeRP7yvyct"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Every effort moves you stand here you stand here you stand here you stand'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, tokenizer, start_context, max_tokens, device, top_k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "162419712"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save({\"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"model.pth\", weights_only=True)\n",
        "model = GPT(cfg).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Every effort moves you stand here you stand here you stand here you stand'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model, tokenizer, start_context, max_tokens, device, top_k=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
