{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbl1xR9Jspp58HLijcokaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max-monty/llm_from_scratch/blob/master/Infinite_Shel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ayr_UpuxHXtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9KK4p8bSFxtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjyEWbilKGYW",
        "outputId": "e32f4ffa-d18f-4766-8260-67780aa7f74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "GJlmSE8MFM6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "xbV30nykFtGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JjT8tGr9Ef0m"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_128M = {\n",
        "    \"tokenizer\": \"gpt2\",    # Tokenizer\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"context_len\": 256,    # Context length\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False,      # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "# GPT_CONFIG_128M = {\n",
        "#     \"tokenizer\": \"gpt2\",    # Tokenizer\n",
        "#     \"vocab_size\": 50257,    # Vocabulary size\n",
        "#     \"n_layers\": 4,         # Number of layers\n",
        "#     \"n_heads\": 4,          # Number of attention heads\n",
        "#     \"emb_dim\": 256,         # Embedding dimension\n",
        "#     \"context_len\": 256,    # Context length\n",
        "#     \"drop_rate\": 0.1,       # Dropout rate\n",
        "#     \"qkv_bias\": False,      # Query-Key-Value bias\n",
        "#     \"batch_size\": 16,       # Batch size\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw Data"
      ],
      "metadata": {
        "id": "ZGqkG-F4Ikfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2oeaDmIkKv",
        "outputId": "0d35aadd-34c6-420f-ac91-bae54c6412ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/data/'\n",
        "sidewalk_path = path + 'sidewalk.txt'\n",
        "verdict_path = path + 'verdict.txt'\n",
        "\n",
        "with open(sidewalk_path, 'r') as f:\n",
        "  sidewalk = f.read()\n",
        "\n",
        "with open(verdict_path, 'r') as f:\n",
        "  verdict = f.read()"
      ],
      "metadata": {
        "id": "U_AxT6PiJD-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "FihGcc9bF3Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "HQBU2evtF-Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, tokenizer, context_size):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        enc_txt = tokenizer.encode(text)\n",
        "        for i in range(0, len(enc_txt) - context_size):\n",
        "            x = enc_txt[i:i+context_size]\n",
        "            y = enc_txt[i+1:i+context_size+1]\n",
        "            self.x.append(torch.tensor(x))\n",
        "            self.y.append(torch.tensor(y))\n",
        "        self.x = torch.stack(self.x)\n",
        "        self.y = torch.stack(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def load_data(self, batch_size=32, shuffle=True):\n",
        "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle, drop_last=True, num_workers=0)"
      ],
      "metadata": {
        "id": "PpfqANTcFFOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "rA-3_MnQGAw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization"
      ],
      "metadata": {
        "id": "Hk2TYVHLGKos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.ones(cfg[\"emb_dim\"]))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(cfg[\"emb_dim\"]))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        normalized = (x - mean) / (std + self.eps)\n",
        "        return normalized * self.weight + self.bias"
      ],
      "metadata": {
        "id": "AdGUPAmjGHbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token and Posistion Embedding"
      ],
      "metadata": {
        "id": "RgRex_HfGWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingLayer(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, max_len):\n",
        "        super().__init__()\n",
        "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding = torch.nn.Embedding(max_len, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok_embed = self.token_embedding(x)\n",
        "        pos_embed = self.position_embedding(torch.arange(x.shape[1], device=x.device))\n",
        "        return tok_embed + pos_embed"
      ],
      "metadata": {
        "id": "6rMWfNqWGXUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-head Attention"
      ],
      "metadata": {
        "id": "NB25YuFsGnpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, n_heads, drop_rate, qkv_bias):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_out // n_heads\n",
        "        self.q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = torch.nn.Dropout(drop_rate)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        Q = self.q(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        attention_scores = Q @ K.transpose(-2, -1)\n",
        "        mask = self.mask[:T, :T]\n",
        "        attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "        attention_weights = torch.softmax(attention_scores / (self.head_dim ** 0.5), dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        context_vectors = attention_weights @ V\n",
        "        context_vectors = context_vectors.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.out_proj(context_vectors)"
      ],
      "metadata": {
        "id": "2s03Sub2Gnwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "qV9B988jG-EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "fYHH-oqwG-Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "_inSEITVHGvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_len\"],\n",
        "            n_heads=cfg[\"n_heads\"],\n",
        "            drop_rate=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        self.ff = MLP(cfg)\n",
        "        self.norm_1 = LayerNorm(cfg)\n",
        "        self.norm_2 = LayerNorm(cfg)\n",
        "        self.dropout = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        short_cut = x\n",
        "        x = self.norm_1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "\n",
        "        short_cut = x\n",
        "        x = self.norm_2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "        return x"
      ],
      "metadata": {
        "id": "uXBI9RmhHG1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "h1jDAQl9HOyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = EmbeddingLayer(cfg[\"vocab_size\"], cfg[\"emb_dim\"], cfg[\"context_len\"])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.ln_f = LayerNorm(cfg)\n",
        "        self.out_head = torch.nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop_emb(self.embedding_layer(x))\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        return self.out_head(x)"
      ],
      "metadata": {
        "id": "SP_R3CknHOfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "RKibo7diKR4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "mx7fiXTfNxU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(cfg, data, tokenizer, batch_size):\n",
        "    dataset = Dataset(data, tokenizer, context_size=cfg[\"context_len\"])\n",
        "    dataloader = dataset.load_data(batch_size, shuffle=True)\n",
        "    #iter_dataloader = iter(dataloader)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "J6ZWiD7hKUKV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "kLNm_KK7OWC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "  train_data = data[:int(len(data) * 0.9)]\n",
        "  val_data = data[int(len(data) * 0.9):]\n",
        "  return train_data, val_data"
      ],
      "metadata": {
        "id": "AfVxjSBqOWJY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Train-Val Sets"
      ],
      "metadata": {
        "id": "uvZcUwjpOvZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(cfg, data, tokenizer, batch_size):\n",
        "  train_data, val_data = split_data(data)\n",
        "  train_dataloader = load_data(cfg, train_data, tokenizer, batch_size)\n",
        "  val_dataloader = load_data(cfg, val_data, tokenizer, batch_size)\n",
        "  return train_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "27Fuh9cgOvgD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Loss (Batch)"
      ],
      "metadata": {
        "id": "kco9LtpXS2rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(model, x, y, device):\n",
        "    logits = model(x.to(device))\n",
        "    targets = y.to(device)\n",
        "    # B, T, C = logits.shape\n",
        "    # loss = torch.nn.functional.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), targets.flatten())\n",
        "    return loss"
      ],
      "metadata": {
        "id": "KFzSnw_TS2yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Loss (Loader)"
      ],
      "metadata": {
        "id": "gXfwUPkFTjTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(model, dataloader, device, num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    if i >= num_batches:\n",
        "      break\n",
        "    loss = calc_loss_batch(model, x, y, device)\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "U-8pZsGzTjaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model"
      ],
      "metadata": {
        "id": "o4edQP0DZ576"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, eval_iter, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(model, train_loader, device, eval_iter)\n",
        "    val_loss = calc_loss_loader(model, val_loader, device, eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "UaJMSNUcZ6BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Tokens Ids"
      ],
      "metadata": {
        "id": "3xHVTBQBeDC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tokens(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor"
      ],
      "metadata": {
        "id": "q0F_G5LweDJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Ids to Text"
      ],
      "metadata": {
        "id": "5rM6GXkjeqQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(tokens, tokenizer):\n",
        "  flat = tokens.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "XQHS3taNeqXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Sample"
      ],
      "metadata": {
        "id": "SzW5oSt1b61d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, idx, max_tokens, context_size):\n",
        "  for _ in range(max_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "JzcVzZyHcgQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sample(model, tokenizer, context, max_tokens, device):\n",
        "  model.eval()\n",
        "  context_size = model.embedding_layer.position_embedding.weight.shape[0]\n",
        "  idx = text_to_tokens(context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    idx = generate_text(model, idx, max_tokens, context_size)\n",
        "  return tokens_to_text(idx, tokenizer)"
      ],
      "metadata": {
        "id": "bGPnUQhGb67U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "yXptd16PLDu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Parameters"
      ],
      "metadata": {
        "id": "liqnCJXpLPoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = GPT_CONFIG_128M\n",
        "tokenizer = tiktoken.get_encoding(cfg[\"tokenizer\"])\n",
        "data = verdict #sidewalk\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 10\n",
        "eval_freq = 100\n",
        "eval_iter = 5\n",
        "max_tokens = 10\n",
        "start_context = \"Every effort moves you\"\n",
        "batch_size = 8"
      ],
      "metadata": {
        "id": "HJvtCzViLUKb"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Model"
      ],
      "metadata": {
        "id": "KZWmmNR3L-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(cfg).to(device)"
      ],
      "metadata": {
        "id": "tpjYdhdMLXq0"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Optimizer"
      ],
      "metadata": {
        "id": "EweKFVv9MXp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "x9rZf9mvMD03"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "FXuR9ltBM4_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_val_split(cfg, data, tokenizer, batch_size)"
      ],
      "metadata": {
        "id": "BHrZbjj4MdBh"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "CIPp1xVPYzhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, num_epochs, device,\n",
        "          eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(model, x, y, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += x.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, eval_iter, device)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Epoch: {epoch + 1}, Step: {global_step:06d}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}\")\n",
        "        print(generate_sample(model, tokenizer, start_context, max_tokens , device))\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "1Gi07O4jYzox"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, track_tokens_seen = train_model(model, train, val, optimizer, epochs, device, eval_freq, eval_iter, start_context, tokenizer)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TiigHs72Tb52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}