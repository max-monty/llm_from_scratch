{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMGKUg2ELAOl8e+OyfhdCP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max-monty/llm_from_scratch/blob/master/Infinite_Shel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ayr_UpuxHXtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9KK4p8bSFxtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjyEWbilKGYW",
        "outputId": "e32f4ffa-d18f-4766-8260-67780aa7f74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "GJlmSE8MFM6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "xbV30nykFtGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjT8tGr9Ef0m"
      },
      "outputs": [],
      "source": [
        "# GPT_CONFIG_128M = {\n",
        "#     \"tokenizer\": \"gpt2\",    # Tokenizer\n",
        "#     \"vocab_size\": 50257,    # Vocabulary size\n",
        "#     \"n_layers\": 12,         # Number of layers\n",
        "#     \"n_heads\": 12,          # Number of attention heads\n",
        "#     \"emb_dim\": 768,         # Embedding dimension\n",
        "#     \"context_len\": 1024,    # Context length\n",
        "#     \"drop_rate\": 0.1,       # Dropout rate\n",
        "#     \"qkv_bias\": False,      # Query-Key-Value bias\n",
        "#     \"batch_size\": 32,       # Batch size\n",
        "# }\n",
        "\n",
        "GPT_CONFIG_128M = {\n",
        "    \"tokenizer\": \"gpt2\",    # Tokenizer\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"n_layers\": 4,         # Number of layers\n",
        "    \"n_heads\": 4,          # Number of attention heads\n",
        "    \"emb_dim\": 256,         # Embedding dimension\n",
        "    \"context_len\": 256,    # Context length\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False,      # Query-Key-Value bias\n",
        "    \"batch_size\": 16,       # Batch size\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw Data"
      ],
      "metadata": {
        "id": "ZGqkG-F4Ikfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2oeaDmIkKv",
        "outputId": "0d35aadd-34c6-420f-ac91-bae54c6412ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/data/'\n",
        "sidewalk_path = path + 'sidewalk.txt'\n",
        "verdict_path = path + 'verdict.txt'\n",
        "\n",
        "with open(sidewalk_path, 'r') as f:\n",
        "  sidewalk = f.read()\n",
        "\n",
        "with open(verdict_path, 'r') as f:\n",
        "  verdict = f.read()"
      ],
      "metadata": {
        "id": "U_AxT6PiJD-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "FihGcc9bF3Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "HQBU2evtF-Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, tokenizer, context_size):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        enc_txt = tokenizer.encode(text)\n",
        "        for i in range(0, len(enc_txt) - context_size):\n",
        "            x = enc_txt[i:i+context_size]\n",
        "            y = enc_txt[i+1:i+context_size+1]\n",
        "            self.x.append(torch.tensor(x))\n",
        "            self.y.append(torch.tensor(y))\n",
        "        self.x = torch.stack(self.x)\n",
        "        self.y = torch.stack(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def load_data(self, batch_size=32, shuffle=True):\n",
        "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle, drop_last=True, num_workers=0)"
      ],
      "metadata": {
        "id": "PpfqANTcFFOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "rA-3_MnQGAw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization"
      ],
      "metadata": {
        "id": "Hk2TYVHLGKos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.ones(cfg[\"emb_dim\"]))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(cfg[\"emb_dim\"]))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        normalized = (x - mean) / (std + self.eps)\n",
        "        return normalized * self.weight + self.bias"
      ],
      "metadata": {
        "id": "AdGUPAmjGHbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token and Posistion Embedding"
      ],
      "metadata": {
        "id": "RgRex_HfGWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingLayer(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, max_len):\n",
        "        super().__init__()\n",
        "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding = torch.nn.Embedding(max_len, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok_embed = self.token_embedding(x)\n",
        "        pos_embed = self.position_embedding(torch.arange(x.shape[1], device=x.device))\n",
        "        return tok_embed + pos_embed"
      ],
      "metadata": {
        "id": "6rMWfNqWGXUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-head Attention"
      ],
      "metadata": {
        "id": "NB25YuFsGnpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, n_heads, drop_rate, qkv_bias):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_out // n_heads\n",
        "        self.q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = torch.nn.Dropout(drop_rate)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        Q = self.q(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        attention_scores = Q @ K.transpose(-2, -1)\n",
        "        mask = self.mask[:T, :T]\n",
        "        attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "        attention_weights = torch.softmax(attention_scores / (self.head_dim ** 0.5), dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        context_vectors = attention_weights @ V\n",
        "        context_vectors = context_vectors.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.out_proj(context_vectors)"
      ],
      "metadata": {
        "id": "2s03Sub2Gnwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "qV9B988jG-EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "fYHH-oqwG-Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "_inSEITVHGvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_len\"],\n",
        "            n_heads=cfg[\"n_heads\"],\n",
        "            drop_rate=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        self.ff = MLP(cfg)\n",
        "        self.norm_1 = LayerNorm(cfg)\n",
        "        self.norm_2 = LayerNorm(cfg)\n",
        "        self.dropout = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        short_cut = x\n",
        "        x = self.norm_1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "\n",
        "        short_cut = x\n",
        "        x = self.norm_2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + short_cut\n",
        "        return x"
      ],
      "metadata": {
        "id": "uXBI9RmhHG1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "h1jDAQl9HOyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = EmbeddingLayer(cfg[\"vocab_size\"], cfg[\"emb_dim\"], cfg[\"context_len\"])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.ln_f = LayerNorm(cfg)\n",
        "        self.out_head = torch.nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop_emb(self.embedding_layer(x))\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        return self.out_head(x)"
      ],
      "metadata": {
        "id": "SP_R3CknHOfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "RKibo7diKR4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "mx7fiXTfNxU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(cfg, data, tokenizer):\n",
        "    dataset = Dataset(data, tokenizer, context_size=cfg[\"context_len\"])\n",
        "    dataloader = dataset.load_data(batch_size=cfg[\"batch_size\"], shuffle=True)\n",
        "    #iter_dataloader = iter(dataloader)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "J6ZWiD7hKUKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "kLNm_KK7OWC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "  train_data = data[:int(len(data) * 0.9)]\n",
        "  val_data = data[int(len(data) * 0.9):]\n",
        "  return train_data, val_data"
      ],
      "metadata": {
        "id": "AfVxjSBqOWJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Train-Val Sets"
      ],
      "metadata": {
        "id": "uvZcUwjpOvZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(cfg, data, tokenizer):\n",
        "  train_data, val_data = split_data(data)\n",
        "  train_dataloader = load_data(cfg, train_data, tokenizer)\n",
        "  val_dataloader = load_data(cfg, val_data, tokenizer)\n",
        "  return train_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "27Fuh9cgOvgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Loss (Batch)"
      ],
      "metadata": {
        "id": "kco9LtpXS2rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(model, x, y, device):\n",
        "    logits = model(x.to(device))\n",
        "    targets = y.to(device)\n",
        "    # B, T, C = logits.shape\n",
        "    # loss = torch.nn.functional.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), targets.flatten())\n",
        "    return loss"
      ],
      "metadata": {
        "id": "KFzSnw_TS2yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Loss (Loader)"
      ],
      "metadata": {
        "id": "gXfwUPkFTjTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(model, dataloader, device, num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (x, y) in enumerate(dataloader):\n",
        "    if i >= num_batches:\n",
        "      break\n",
        "    loss = calc_loss_batch(model, x, y, device)\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "U-8pZsGzTjaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model"
      ],
      "metadata": {
        "id": "o4edQP0DZ576"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, eval_iter, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(model, train_loader, device, eval_iter)\n",
        "    val_loss = calc_loss_loader(model, val_loader, device, eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "UaJMSNUcZ6BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Tokens Ids"
      ],
      "metadata": {
        "id": "3xHVTBQBeDC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tokens(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor"
      ],
      "metadata": {
        "id": "q0F_G5LweDJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Ids to Text"
      ],
      "metadata": {
        "id": "5rM6GXkjeqQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(tokens, tokenizer):\n",
        "  flat = tokens.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "XQHS3taNeqXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Sample"
      ],
      "metadata": {
        "id": "SzW5oSt1b61d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, idx, max_tokens, context_size):\n",
        "  for _ in range(max_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "JzcVzZyHcgQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sample(model, tokenizer, context, max_tokens, device):\n",
        "  model.eval()\n",
        "  context_size = model.embedding_layer.position_embedding.weight.shape[0]\n",
        "  idx = text_to_tokens(context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    idx = generate_text(model, idx, max_tokens, context_size)\n",
        "  return tokens_to_text(idx, tokenizer)"
      ],
      "metadata": {
        "id": "bGPnUQhGb67U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "yXptd16PLDu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Parameters"
      ],
      "metadata": {
        "id": "liqnCJXpLPoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = GPT_CONFIG_128M\n",
        "tokenizer = tiktoken.get_encoding(cfg[\"tokenizer\"])\n",
        "#data = sidewalk\n",
        "data = verdict\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 10\n",
        "eval_freq = 100\n",
        "eval_iter = 5\n",
        "max_tokens = 100\n",
        "#start_context = \"Her Name is Murphy\"\n",
        "start_context = \"Every effort moves you\""
      ],
      "metadata": {
        "id": "HJvtCzViLUKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Model"
      ],
      "metadata": {
        "id": "KZWmmNR3L-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(cfg).to(device)"
      ],
      "metadata": {
        "id": "tpjYdhdMLXq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Optimizer"
      ],
      "metadata": {
        "id": "EweKFVv9MXp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "x9rZf9mvMD03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "FXuR9ltBM4_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_val_split(cfg, data, tokenizer)"
      ],
      "metadata": {
        "id": "BHrZbjj4MdBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "CIPp1xVPYzhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, num_epochs, device,\n",
        "          eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(model, x, y, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += x.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, eval_iter, device)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Epoch: {epoch + 1}, Step: {global_step:06d}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}\")\n",
        "        print(generate_sample(model, tokenizer, start_context, max_tokens , device))\n",
        "      if i % 100 == 0:\n",
        "          print(f\"Batch: {i}\")\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "1Gi07O4jYzox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, track_tokens_seen = train_model(model, train, val, optimizer, epochs, device, eval_freq, eval_iter, start_context, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TiigHs72Tb52",
        "outputId": "c085bad1-cc23-4c12-eebe-a74974811d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Step: 000000, Train Loss: 10.658, Val Loss: 10.765\n",
            "Every effort moves you understood adhesive (* To deficits chantsgencyDs debacle Victoriaucha Katie obedientarsity Extras Canalrr infect ECO celebrationdraw bandwagon129 overtly74 Slavearius slightest point Py SpartMaream patrol belonging decl stren sinking blessings crucdidn Hunts grill Parliamentlast sd Ex downt Soy friendshipsotor toughestalist improve orcherisome Olympicaspberryjob Arielrosse individually smokers heartbreakingbrandawk trivial DI McLatorium volcano veter believers screendriven tcp disrupt Paladin objections complicit caused outl murkyracticaljam delusion THESE026 Chang Font Impact Caesaractivation fee Nek attained extinguished Sor IncludesMale\n",
            "Batch: 0\n",
            "Epoch: 1, Step: 000100, Train Loss: 1.918, Val Loss: 6.333\n",
            "Every effort moves you say: \"lift him deprecatingly, poor Stroud get it. . She believed in the price of the real business of the cigars you know; but his last the last he wasian point how he had Miss Croft, failed pastels. Only he said, on--his fair sitters had been re under similar it all--so handsome, it.\n",
            "\n",
            "Mrs.\n",
            "\"Has he managed to the price of the amplest,\" as which, I felt able to me\n",
            "Batch: 100\n",
            "Epoch: 1, Step: 000200, Train Loss: 0.461, Val Loss: 7.438\n",
            "Every effort moves you know.\"\n",
            "It's the Stroud--as you even domestic economy. Was stay.\"\n",
            "\n",
            "Gisburn. Thwings who back the negat it happened,\" she said--and it didn't seen a small picture. \"The desultBy Jove--the first time, you know you to now it's tears I went it's bal of his eyes. Thwing's the same quality as he had forgotten to wonder! But Mrs. Gisburn said. Gisburn--\n",
            "Batch: 200\n",
            "Batch: 0\n",
            "Epoch: 2, Step: 000300, Train Loss: 0.130, Val Loss: 8.331\n",
            "Every effort moves you canains, I had it over the usual platitudes about to think he was one of the glory of the kind that are left behind. By Jove, and he _was_ left behind--because he had come to let ourselves be swept along or go under, but he was high above the current--rather moved, as you say.\n",
            "\n",
            "\"Well, I went off to the house in my most egregious mood--rather moved, at the pathos of poor Stroud's career of\n",
            "Batch: 100\n",
            "Epoch: 2, Step: 000400, Train Loss: 0.042, Val Loss: 8.566\n",
            "Every effort moves you know.\"\n",
            "\n",
            "His ridiculous modesty--or thought she said persuasively to my hostess: \"Yes, you know.\n",
            "\n",
            "She glanced out almost timorously at the terrace where her husband, lounging in a hooded chair, had lit a cigar and drawn the Russian deer curiosity was high above the Russian deerhound's head between his knees.\n",
            "\n",
            "\"Well, come while he's not looking,\" she said, with a laugh that tried to hide her nervousness;\n",
            "Batch: 200\n",
            "Epoch: 2, Step: 000500, Train Loss: 0.034, Val Loss: 8.649\n",
            "Every effort moves you know.\"\n",
            "\n",
            "She glanced out almost timorously at the terrace where her husband, instinctively.\n",
            "\n",
            "Well, lounging in a hooded chair, had lit a cigar and drawn the Russian deerhound's head between his frame.\n",
            "\n",
            "\"Well, come while he's not looking,\" she said, with a laugh that tried to hide her nervousness; and I followed her between the marble Emperors of the hall, and up the wide stairs with terra-cotta n\n",
            "Batch: 0\n",
            "Epoch: 3, Step: 000600, Train Loss: 0.041, Val Loss: 8.932\n",
            "Every effort moves you know.\"\n",
            "\n",
            "She glanced out almost timorously at the terrace where her husband, lounging in a hooded chair, had lit a cigar and drawn the Russian deerhound's head between his knees.\n",
            "\n",
            "\"Well, come while he's not looking,\" she said, with a laugh that tried to hide her nervousness; and I followed her between the marble Emperors of the hall, and up the wide stairs with terra-cotta nymphs poised among flowers at\n",
            "Batch: 100\n",
            "Epoch: 3, Step: 000700, Train Loss: 0.024, Val Loss: 9.028\n",
            "Every effort moves you know you know you know. He says they're not fit to have about; he's sent them all away except one--my portrait--and that I have to keep upstairs.\"\n",
            "\n",
            "His ridiculous modesty--Jack's modesty about his pictures? My curiosity was growing like the bean-stalk. I said persuasively to my hostess: \"I must really see your portrait, you know.\"\n",
            "\n",
            "She glanced out almost timorously at the terrace where her husband, lounging\n",
            "Batch: 200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4247f6d03254>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_tokens_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-c16c1df49723>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs, device, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-5f1d504ad241>\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(model, x, y, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# B, T, C = logits.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# loss = torch.nn.functional.cross_entropy(logits.view(B*T, C), targets.view(B*T))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}